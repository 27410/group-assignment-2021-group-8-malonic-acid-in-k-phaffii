{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aae3ba80-eba4-4d67-9d97-fc29cfbd2d17",
   "metadata": {},
   "source": [
    "# **OptCouple**\n",
    "\n",
    "OptCouple is an algorithm that combines knock-outs, knock-ins and media additions to couple metabolic flux towards a target metabolite with biomass accumulation. OptKnock tries to identify knock out targets which optimize metabolic flux towards a target metabolite by coupling production to growth.\n",
    "\n",
    "Most of this code is extracted from the supplementary material of [1]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8708b465-2780-4c07-9eb6-6254290a4f10",
   "metadata": {},
   "source": [
    "## **NOTE: This analysis did not work!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f03935f6-f649-4c47-bf2a-e27730548b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dependencies\n",
    "from cobra.io import read_sbml_model\n",
    "import os\n",
    "os.environ[\"OPTLANG_USE_SYMENGINE\"] = \"False\"\n",
    "import cameo\n",
    "import cobra\n",
    "from cobra.test import create_test_model\n",
    "from optlang.duality import convert_linear_problem_to_dual\n",
    "import logging\n",
    "from cameo.models import universal\n",
    "from cameo.data import metanetx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51660bcc-c57a-4fbf-8336-2eeaccbdabdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb761848-d341-46ee-b12a-ff2ac9fd3f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "\n",
    "#cobra.show_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc276c34-841e-4858-90af-d2402adad39d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2022-01-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\cobra\\core\\group.py:107: UserWarning: need to pass in a list\n",
      "  warn(\"need to pass in a list\")\n"
     ]
    }
   ],
   "source": [
    "# Read the Komagataella phaffii model with malonic acid pathway\n",
    "model = read_sbml_model('../src/models/gen/iMT1026-v3Optimization.xml')\n",
    "model.reactions.ATPM.delete() # ATPM has forced flux bounds, which is not compatible with OptCouple\n",
    "\n",
    "# Change carbon source to methanol\n",
    "medium = model.medium\n",
    "medium['Ex_glyc'] = 0\n",
    "medium['Ex_meoh'] = 6\n",
    "model.medium = medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10f44f59-4b25-4234-b28a-903bddfb9106",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td><strong>Name</strong></td>\n",
       "                <td>iMT1026v3</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Memory address</strong></td>\n",
       "                <td>0x023286b7e7f0</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of metabolites</strong></td>\n",
       "                <td>1708</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of reactions</strong></td>\n",
       "                <td>2240</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of groups</strong></td>\n",
       "                <td>77</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Objective expression</strong></td>\n",
       "                <td>1.0*Ex_biomass - 1.0*Ex_biomass_reverse_5354f</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Compartments</strong></td>\n",
       "                <td>Vacuole, Cytosol, Mitochondria, Peroxisome, Extracellular space, Endoplasmic Reticulum, Golgi Apparatus, Nucleus, Mitochondrial intermembrane space</td>\n",
       "            </tr>\n",
       "          </table>"
      ],
      "text/plain": [
       "<Model iMT1026v3 at 0x23286b7e7f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605381d1-50ca-460e-b317-89a15f29cdff",
   "metadata": {},
   "source": [
    "#### OptCouple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86dd4b6d-e5e8-46a0-a474-b307e34fc28a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Select reactions to exclude from knock-out\n",
    "# Make a set of reactions that you do not want to consider for knock-out, as they are spontaneous or diffusion reactions, or reactions that have no gene information. \n",
    "# Make sure that the target reaction is not in this set!\n",
    "# Define reactions that should be excluded from knock-out as these will be impossible in practice.\n",
    "\n",
    "def determine_reactions_to_exclude(model, spontaneous_gene_id=None, ids_not_to_exclude=None):\n",
    "    \"\"\"\n",
    "    Creates a set of reaction ids from the cobra model that should not be suggested as modification by the algorithm.\n",
    "    This set includes reactions that occur spontaneously, reactions that have no gene information in the model \n",
    "    and transport reactions that occur as result of diffusion.\n",
    "    \n",
    "    Arguments:\n",
    "    model: a cobra model\n",
    "    spontaneous_gene_id: the gene id (string) that spontaneous reactions are assigned to\n",
    "    ids_not_to_exclude: set of gene ids that should not be in the resulting set\n",
    "    \"\"\"\n",
    "    \n",
    "    exclude_reaction_ids = set()\n",
    "\n",
    "    # Exclude reactions for which no gene is available, contain \"diffusion\" in their description\n",
    "    # or are assigned to the spontaneous gene id.\n",
    "    for r in model.reactions:\n",
    "        if not r.genes or \"diffusion\" in r.name or spontaneous_gene_id in [g.id for g in r.genes]: \n",
    "            exclude_reaction_ids.add(r.id)\n",
    "            \n",
    "    # Make sure that the 'ids_not_to_exclude' reactions are not in the set      \n",
    "    if ids_not_to_exclude is not None:\n",
    "        for r_id in ids_not_to_exclude:\n",
    "            exclude_reaction_ids.discard(r_id)\n",
    "\n",
    "    return exclude_reaction_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa1b87ac-7ee7-480b-b9ea-0ea2d291ce0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run function excluded reactions\n",
    "exclude_reaction_ids = determine_reactions_to_exclude(model, ids_not_to_exclude=['EX_mac_e', 'mac_etoEX', 'MSADH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1b07db6-6ed4-4b8e-bb2d-79eb56d0b33b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Load universal model for knock-ins\n",
    "# The universal model used is taken from cameo.models.metanetx_universal_model_bigg and converted into BiGG identifiers using the conversion dictionary cameo.data.metanetx.mnx2bigg, \n",
    "# as done in the \"03 TheAlgorithm EcoliCore2 - methylation\" notebook.\n",
    "\n",
    "# Load a universal BiGG model from cameo, consisting of 2819 metabolites and 6416 reactions.\n",
    "univ_model = cobra.io.load_json_model(\"Universal_BiGG_model.json\")\n",
    "# univ_model\n",
    "\n",
    "# Print all metabolites and reactions in a model. For debugging/searching:\n",
    "# for m in univ_model.metabolites:\n",
    "#     print(m.id, m.name, m.compartment, sep=\"\\t\")\n",
    "# for r in univ_model.reactions:\n",
    "#     print(r.id, r.name, r.reaction, r.compartments, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bc69b32-a698-4605-85ec-52194e3509f3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Add relevant universal reactions to the native model\n",
    "\n",
    "def fuse_native_with_universal_model(native_model, universal_model, number_of_knockins, include_demands=False):\n",
    "    \"\"\"\n",
    "    Merges the native cobra model with the relevant reactions from the universal_model. \n",
    "    The universal reactions that could be fully connected with the specified number of knockins are selected.\n",
    "    The native reactions are flagged with a type attribute 'native'. Reactions from the universal model are assigned the 'heterologous' type.\n",
    "    \n",
    "    Arguments:\n",
    "    native_model: the native cobra model\n",
    "    universal_model: the universal cobra model to select knockins from\n",
    "    include_demands: whether demand reactions from the universal model with matching reactants are added or not\n",
    "    number_of_knockins: the number of knockins on which to base the selection of relevant universal reactions\n",
    "    \"\"\"\n",
    "    # If no fusion of models is needed, but just labeling all native reactions with .type = \"native\":\n",
    "    if number_of_knockins == 0:\n",
    "        for r in native_model.reactions:\n",
    "            r.type = \"native\"\n",
    "        return native_model\n",
    "    \n",
    "    # Not to modify the models given as arguments\n",
    "    fused_model = native_model.copy()\n",
    "    reduced_universal_model = universal_model.copy()\n",
    "    \n",
    "    # Keep track of native and heterologous reactions by adding a .type attribute to each reaction:\n",
    "    for r in fused_model.reactions:\n",
    "        r.type = \"native\"\n",
    "        \n",
    "    # Make a set structure to identify reactions in the universal model that are duplicates of the native reactions\n",
    "    # reactions = set(     # This set contains representations of all reactions\n",
    "    #     frozenset(       # This frozenset contains 1 frozenset with all reactants and 1 with all products\n",
    "    #         frozenset(   # These 2 frozensets contains all the metabolites in either products or reactants\n",
    "    #             tuple(metabolite_id, coefficient)  # Coefficients are made positive if the reaction is reversible\n",
    "    #         )                                      # Otherwise, reactant coefficients are negative\n",
    "    #     )\n",
    "    # )\n",
    "\n",
    "    native_reactions_set = set()\n",
    "    for r in fused_model.reactions:\n",
    "        product_list = [] # Storing the metabolite ids for all products\n",
    "        reactant_list = []\n",
    "        prod_coef_list = [] # Storing the matching coefficients\n",
    "        reac_coef_list = []\n",
    "        # Make lists of the product and reactant ids and their coefficients\n",
    "        for m in r.products:\n",
    "            product_list.append(m.id)\n",
    "        for m in r.reactants:\n",
    "            reactant_list.append(m.id)        \n",
    "        for c in r.get_coefficients(r.products):\n",
    "            prod_coef_list.append(c)\n",
    "        if r.reversibility:\n",
    "            for c in r.get_coefficients(r.reactants):\n",
    "                reac_coef_list.append(-c) # Remove negative sign from coefficients\n",
    "        else:\n",
    "            for c in r.get_coefficients(r.reactants):\n",
    "                reac_coef_list.append(c) # Keep the negative sign to indicate direction\n",
    "        # Zip these lists to make tuples of (metabolite, coefficient) pairs\n",
    "        productset = frozenset(zip(product_list, prod_coef_list))\n",
    "        reactantset = frozenset(zip(reactant_list, reac_coef_list))\n",
    "        reactionset = set()\n",
    "        reactionset.add(reactantset)\n",
    "        reactionset.add(productset)\n",
    "        native_reactions_set.add(frozenset(reactionset))\n",
    "        #print(native_reactions_set)\n",
    "    \n",
    "    # Remove reactions from the universal model that are boundary reactions (if include_demands is not set to True), \n",
    "    # or duplicates of the native model used\n",
    "    reactions_to_remove = set()\n",
    "    for r in reduced_universal_model.reactions:\n",
    "        # Create the same structure as above for this reaction. Compare if it is among the native reactions.\n",
    "        product_list = []\n",
    "        reactant_list = []\n",
    "        prod_coef_list = []\n",
    "        reac_coef_list = []\n",
    "        # Make lists of the product and reactant ids and their coefficients\n",
    "        for m in r.products:\n",
    "            product_list.append(m.id)\n",
    "        for m in r.reactants:\n",
    "            reactant_list.append(m.id)        \n",
    "        for c in r.get_coefficients(r.products):\n",
    "            prod_coef_list.append(c)\n",
    "        if r.reversibility:\n",
    "            for c in r.get_coefficients(r.reactants):\n",
    "                reac_coef_list.append(-c) # Remove negative sign from coefficients\n",
    "        else:\n",
    "            for c in r.get_coefficients(r.reactants):\n",
    "                reac_coef_list.append(c) # Keep the negative sign to indicate direction\n",
    "        # Zip these lists to make tuples of (metabolite, coefficient) pairs\n",
    "        productset = frozenset(zip(product_list, prod_coef_list))\n",
    "        reactantset = frozenset(zip(reactant_list, reac_coef_list))\n",
    "        reactionset = set()\n",
    "        reactionset.add(reactantset)\n",
    "        reactionset.add(productset)\n",
    "        \n",
    "        if (r.products == [] and not include_demands) or                 reactionset in native_reactions_set:\n",
    "            reactions_to_remove.add(r)\n",
    "\n",
    "    reduced_universal_model.remove_reactions(reactions_to_remove)\n",
    "    \n",
    "    \n",
    "    # Add the relevant reactions from universal model to the organism's native model, \n",
    "    # based on the connection of its metabolites to the native model:\n",
    "    # For every 2 knock-ins allowed, add all reactions that have either all their reactants or all products present in the model so far.\n",
    "    # This means that knock-in pathways are build from both start and end, which will connect at some point if enough knock-ins are allowed.\n",
    "    # Filling the gap from two sides is needed to take reversible reactions into account, which cause problems if building only from the reactant side. \n",
    "    # The last knock-in (number_of_knockins = 1) allowed should be connected to the model by both all reactants and products in order to carry flux\n",
    "    while number_of_knockins > 0:\n",
    "        model_metabolite_ids = [m.id for m in fused_model.metabolites]\n",
    "        for r in reduced_universal_model.reactions:\n",
    "            if (number_of_knockins > 1 and all(m.id in model_metabolite_ids for m in r.reactants) or             (r.products != [] and all(m.id in model_metabolite_ids for m in r.products))) or             (number_of_knockins == 1 and all(m.id in model_metabolite_ids for m in r.metabolites)):    \n",
    "                    add = r.copy()\n",
    "                    add.type = \"heterologous\"\n",
    "                    fused_model.add_reaction(add)\n",
    "        number_of_knockins -= 2\n",
    "\n",
    "               \n",
    "    # Remove all reactions that can't carry flux in the end, \n",
    "    # to trim away all added heterologous reactions that are never relevant as a knock-in.\n",
    "    blocked_reactions = cameo.flux_analysis.analysis.find_blocked_reactions(fused_model)\n",
    "    fused_model.remove_reactions([r for r in blocked_reactions])\n",
    "         \n",
    "    return fused_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3547967-2009-4732-b7df-92f9f8c7fd60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td><strong>Name</strong></td>\n",
       "                <td>iMT1026v3</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Memory address</strong></td>\n",
       "                <td>0x023286b7e7f0</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of metabolites</strong></td>\n",
       "                <td>1708</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of reactions</strong></td>\n",
       "                <td>2240</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of groups</strong></td>\n",
       "                <td>77</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Objective expression</strong></td>\n",
       "                <td>1.0*Ex_biomass - 1.0*Ex_biomass_reverse_5354f</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Compartments</strong></td>\n",
       "                <td>Vacuole, Cytosol, Mitochondria, Peroxisome, Extracellular space, Endoplasmic Reticulum, Golgi Apparatus, Nucleus, Mitochondrial intermembrane space</td>\n",
       "            </tr>\n",
       "          </table>"
      ],
      "text/plain": [
       "<Model iMT1026v3 at 0x23286b7e7f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fused_model = fuse_native_with_universal_model(model, univ_model, include_demands=False, number_of_knockins=0)\n",
    "fused_model\n",
    "# For some reason fusing these while allowing knock-ins removes reactions present in iMT1026v3 from the fused model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a90dc8b-ea32-4643-af9f-9de349f94850",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for r in fused_model.reactions:\n",
    "#     if r.type == \"heterologous\":\n",
    "#         print(r)\n",
    "# for r in fused_model.reactions:\n",
    "#     if r.type != \"native\":\n",
    "#         print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07826b12-c4fe-4511-8475-6980db725e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Specify metabolites for medium additions\n",
    "medium_metabolites = []\n",
    "# [\"ala__L_c\", \"arg__L_c\", \"asn__L_c\", \"asp__L_c\", \"cys__L_c\", \"glu__L_c\", \"gln__L_c\", \"gly_c\", \"his__L_c\", \n",
    "# \"ile__L_c\", \"leu__L_c\", \"lys__L_c\", \"met__L_c\", \"phe__L_c\", \"pro__L_c\", \"ser__L_c\", \"thr__L_c\", \"trp__L_c\", \n",
    "# \"tyr__L_c\", \"val__L_c\", \"fru_c\",\"mal__L_c\", \"lac__D_c\", \"ac_c\"]\n",
    "# 24 (L-)Amino acids, D-fructose, L-malate, D-lactate,  acetate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f845d9a-0192-4694-b3a5-c3e259d17409",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Create the MILP problem\n",
    "# This is the main algorithm, creating a MILP problem that when solved returns one or more growth-coupled designs for the target reaction.\n",
    "for reac in model.reactions:\n",
    "    if reac.lower_bound > 0 or reac.upper_bound < 0:\n",
    "        print(reac.id, \"has a forced flux. This should be removed\")\n",
    "        \n",
    "import optlang\n",
    "\n",
    "def setup_growthcoupling_milp(model, target, medium_metabolites, K=2, L=1, M=1, exclude_reaction_ids=set(), remove_blocked=False):\n",
    "    \"\"\"\n",
    "    This function constructs the MILP problem to predict growth-coupled designs with. \n",
    "    K is the number of knockouts that are allowed. L is the number of knockins allowed. M is the number of medium additions.\n",
    "    exclude_reaction_ids takes a list of reaction ids that shouldn't be considered for knockout/in/medium addition \n",
    "    (i.e. spontaneous reactions and exchange reactions). These reactions are thus always allowed to have flux within their model bounds, so this should only be used for excluding knockouts.\n",
    "    \"\"\"\n",
    "    # Check model for forced fluxes, which should not be present. The zero solution must be allowed.\n",
    "    for r in model.reactions:\n",
    "        if r.lower_bound > 0 or r.upper_bound < 0:\n",
    "            raise ValueError(\"%s has a forced flux. Remove the reaction or change its bounds for the function to work.\" % r.id)\n",
    "    \n",
    "    # If a cobra.Reaction is given as target, make the target in just its ID string.\n",
    "    if isinstance(target, cobra.core.Reaction):\n",
    "        target = target.id\n",
    "    \n",
    "    original_model = model\n",
    "    model = model.copy()\n",
    "    \n",
    "    # Add boundary reactions for these metabolites named \"ADD_<metabolitename>\" to the model, with bounds (-10,0).\n",
    "    medium_addition_reactions = []   # List of the addition reactions added to the model\n",
    "    for m in medium_metabolites:\n",
    "        met = model.metabolites.get_by_id(m)\n",
    "        r = model.add_boundary(met, type=\"medium addition\", reaction_id=(\"ADD_\"+m), lb=-10, ub=0)\n",
    "        r.type = \"medium\"\n",
    "        medium_addition_reactions.append(r)\n",
    "    \n",
    "    # Create a set of reactions that should not be considered for knockout (from exclude_from_knockouts list of ids)\n",
    "    excluded_reactions = set()\n",
    "    for r_id in exclude_reaction_ids:\n",
    "        excluded_reactions.add(model.reactions.get_by_id(r_id))\n",
    "    \n",
    "    \n",
    "    # Set the solver to Gurobi for the fastest result. Set to CPLEX if Gurobi is not available.\n",
    "    if \"gurobi\" in cobra.util.solver.solvers.keys():\n",
    "        logger.info(\"Changing solver to Gurobi and tweaking some parameters.\")\n",
    "        if \"gurobi_interface\" not in model.solver.interface.__name__:\n",
    "            model.solver = \"gurobi\"\n",
    "        # The tolerances are set to the minimum value. This gives maximum precision.\n",
    "        problem = model.solver.problem\n",
    "        problem.params.NodeMethod = 1 # primal simplex node relaxation\n",
    "        problem.params.FeasibilityTol = 1e-9 #If a flux limited to 0 by a constraint, which range around it is still considered the same as 0 > set smallest possible\n",
    "        problem.params.OptimalityTol = 1e-3 #how sure the solver has to be about this optimum being really the best it has.\n",
    "        problem.params.IntFeasTol = 1e-9 #If a value is set to an integer, how much may it still vary? > set smallest possible\n",
    "        problem.params.MIPgapAbs = 1e-9\n",
    "        problem.params.MIPgap = 1e-9\n",
    "        problem.params.TimeLimit = 200 # Use max 200 seconds when called, return best solution after that\n",
    "        problem.params.PoolSearchMode = 1 #0 for only finding the optimum, 1 for finding more solutions (but no quality guaranteed), 2 for finding the n best possible solutions \n",
    "        #problem.params.PoolSolutions = 10 # Number of solutions kept when finding the optimal solution\n",
    "        #problem.params.PoolGap = 0.9 # only store solutions within 90% of the optimal objective value\n",
    "\n",
    "    elif \"cplex\" in cobra.util.solver.solvers.keys():\n",
    "        logger.warning(\"Changing solver to CPLEX, as Gurobi is not available. This may cause a big slowdown and limit options afterwards.\")\n",
    "        if \"cplex_interface\" not in model.solver.interface.__name__:\n",
    "            model.solver = \"cplex\"\n",
    "        # The tolerances are set to the minimum value. This gives maximum precision.\n",
    "        problem = model.solver.problem\n",
    "        problem.parameters.mip.strategy.startalgorithm.set(1) # primal simplex node relaxation\n",
    "        problem.parameters.simplex.tolerances.feasibility.set(1e-9) #If a flux limited to 0 by a constraint, which range around it is still considered the same as 0 > set smallest possible\n",
    "        problem.parameters.simplex.tolerances.optimality.set(1e-3) #possibly fine with 1e-3, try if allowed. Is how sure the solver has to be about this optimum being really the best it has.\n",
    "        problem.parameters.mip.tolerances.integrality.set(1e-9) #If a value is set to an integer, how much may it still vary? > set smallest possible\n",
    "        problem.parameters.mip.tolerances.absmipgap.set(1e-9)\n",
    "        problem.parameters.mip.tolerances.mipgap.set(1e-9)\n",
    "        #problem.parameters.mip.pool.relgap.set(0.9) # For populate: find all solutions within 10% of the optimum for relgap = 0.1\n",
    "        #problem.parameters.timelimit.set(200) # Use max 200 seconds for solving\n",
    "        #problem.parameters.mip.limits.populate.set(20) # Find max 20 solutions (=default)\n",
    "   \n",
    "    else:\n",
    "        logger.warning(\"You are trying to run 'OptCouple' with %s. This might not end well.\" %\n",
    "                      model.solver.interface.__name__.split(\".\")[-1])\n",
    "    \n",
    "    # Remove reactions that are blocked: no flux through these reactions possible. This will reduce the search space for the solver, if not done already.\n",
    "    if remove_blocked:\n",
    "        blocked_reactions = cameo.flux_analysis.analysis.find_blocked_reactions(fused_model)\n",
    "        fused_model.remove_reactions(blocked_reactions)\n",
    "        logger.debug(\"Removed \" + str(len(blocked_reactions)) + \" reactions that were blocked\")\n",
    "    \n",
    "    # Make dual\n",
    "    model_without_target = model.copy() # This variable looks unnecessary, but is kept out of fear of messing stuff up\n",
    "    model_without_target.optimize()\n",
    "    dual_problem = convert_linear_problem_to_dual(model_without_target.solver)\n",
    "    logger.debug(\"Dual problem successfully created\")\n",
    "\n",
    "    # Combine primal and dual\n",
    "    primal_problem = model.solver\n",
    "\n",
    "    for var in dual_problem.variables:  # All variables in the dual are copied to the primal\n",
    "        var = primal_problem.interface.Variable.clone(var)\n",
    "        primal_problem.add(var)\n",
    "    for const in dual_problem.constraints:  # All constraints in the dual are copied to the primal\n",
    "        const = primal_problem.interface.Constraint.clone(const, model=primal_problem)\n",
    "        primal_problem.add(const)\n",
    "    logger.debug(\"Dual and primal combined\")\n",
    "\n",
    "    dual_problem.optimize()\n",
    "    \n",
    "    \n",
    "    # Dictionaries to hold the binary control variables: \n",
    "    native_y_vars = {}       # 1 for knockout, 0 for active\n",
    "    heterologous_y_vars = {} # 1 for knockin, 0 for inactive\n",
    "    medium_y_vars = {}       # 1 for medium addition (up to -10), 0 for no addition\n",
    "    \n",
    "    # Now the fun stuff\n",
    "    constrained_dual_vars = set()\n",
    "    \n",
    "    # Fill the dictionaries with binary variables\n",
    "    # For the knockouts: only for the native reactions which are not exchanges\n",
    "    for reaction in [r for r in model.reactions - excluded_reactions if r.type == \"native\"]:\n",
    "\n",
    "        # Add constraint variables\n",
    "        interface = model.solver.interface\n",
    "        y_var = interface.Variable(\"y_\" + reaction.id, type=\"binary\")\n",
    "\n",
    "        # Constrain the primal: flux through reactions maximum within (-1000, 1000), or smaller boundaries defined before\n",
    "        model.solver.add(interface.Constraint(reaction.flux_expression - 1000 * (1 - y_var), ub=0, name=\"primal_y_const_\"+reaction.id+\"_ub\"))\n",
    "        model.solver.add(interface.Constraint(reaction.flux_expression + 1000 * (1 - y_var), lb=0, name=\"primal_y_const_\"+reaction.id+\"_lb\")) \n",
    "\n",
    "        # Constrain the dual\n",
    "        constrained_vars = []\n",
    "\n",
    "        if reaction.upper_bound != 0:\n",
    "            dual_forward_ub = model.solver.variables[\"dual_\" + reaction.forward_variable.name + \"_ub\"]\n",
    "            model.solver.add(interface.Constraint(dual_forward_ub - 1000 * y_var, ub=0))\n",
    "            constrained_vars.append(dual_forward_ub)\n",
    "        if reaction.lower_bound != 0:\n",
    "            dual_reverse_ub = model.solver.variables[\"dual_\" + reaction.reverse_variable.name + \"_ub\"] \n",
    "            model.solver.add(interface.Constraint(dual_reverse_ub - 1000 * y_var, ub=0))\n",
    "            constrained_vars.append(dual_reverse_ub)\n",
    "        constrained_dual_vars.update(constrained_vars)\n",
    "\n",
    "        # Add to dictionary with binary variables for native reactions:\n",
    "        native_y_vars[y_var] = reaction\n",
    "\n",
    "\n",
    "    # For the knockins and medium additions:\n",
    "    for reaction in [r for r in model.reactions - excluded_reactions if r.type == \"heterologous\" or r.type == \"medium\"]:          \n",
    "        # Add constraint variables\n",
    "        interface = model.solver.interface\n",
    "        y_var = interface.Variable(\"y_\" + reaction.id, type=\"binary\")\n",
    "\n",
    "        # Constrain the primal: flux through reactions maximum within (-1000, 1000), or smaller boundaries defined before\n",
    "        model.solver.add(interface.Constraint(reaction.flux_expression - 1000 * y_var, ub=0, name=\"primal_y_const_\"+reaction.id+\"_ub\"))\n",
    "        model.solver.add(interface.Constraint(reaction.flux_expression + 1000 * y_var, lb=0, name=\"primal_y_const_\"+reaction.id+\"_lb\"))  \n",
    "\n",
    "        # Constrain the dual\n",
    "        constrained_vars = []\n",
    "\n",
    "        if reaction.upper_bound != 0:\n",
    "            dual_forward_ub = model.solver.variables[\"dual_\" + reaction.forward_variable.name + \"_ub\"]\n",
    "            model.solver.add(interface.Constraint(dual_forward_ub - 1000 * (1 - y_var), ub=0))\n",
    "            constrained_vars.append(dual_forward_ub)\n",
    "        if reaction.lower_bound != 0:\n",
    "            dual_reverse_ub = model.solver.variables[\"dual_\" + reaction.reverse_variable.name + \"_ub\"]\n",
    "            model.solver.add(interface.Constraint(dual_reverse_ub - 1000 * (1 - y_var), ub=0))\n",
    "            constrained_vars.append(dual_reverse_ub)\n",
    "        constrained_dual_vars.update(constrained_vars)\n",
    "\n",
    "        # Add y variable to the corresponding modifications dictionary\n",
    "        if reaction.type == \"medium\":\n",
    "            medium_y_vars[y_var] = reaction         \n",
    "        elif reaction.type == \"heterologous\":\n",
    "            heterologous_y_vars[y_var] = reaction\n",
    "            \n",
    "    logger.debug(\"Control variables created\")\n",
    "    \n",
    "\n",
    "    # Set the objective\n",
    "    primal_objective = model.solver.objective\n",
    "    dual_objective = interface.Objective.clone(\n",
    "        dual_problem.objective, model=model.solver\n",
    "    )\n",
    "\n",
    "    reduced_expression = optlang.symbolics.Add(\n",
    "        *((c * v) for v, c in dual_objective.expression.as_coefficients_dict().items()\n",
    "        if v not in constrained_dual_vars)\n",
    "    )\n",
    "    dual_objective = interface.Objective(reduced_expression, direction=dual_objective.direction)\n",
    "\n",
    "    full_objective = interface.Objective(primal_objective.expression - dual_objective.expression, direction=\"max\")\n",
    "    model.objective = full_objective\n",
    "    logger.debug(\"Objective created\")\n",
    "    \n",
    "        \n",
    "    # Add number of knockouts constraint. ub=K+1 as the target will be forced to be 1 as well\n",
    "    knockout_number_constraint = model.solver.interface.Constraint(\n",
    "        optlang.symbolics.Add(*native_y_vars), lb=0, ub=K+1, name=\"number_of_knockouts_constraint\"\n",
    "    )\n",
    "    model.solver.add(knockout_number_constraint)\n",
    "   \n",
    "    # Add number of knockins constraint\n",
    "    knockin_number_constraint = model.solver.interface.Constraint(\n",
    "        optlang.symbolics.Add(*heterologous_y_vars), lb=0, ub=L, name=\"number_of_knockins_constraint\"\n",
    "    )\n",
    "    model.solver.add(knockin_number_constraint)\n",
    "  \n",
    "    # Add number of medium additions constraint\n",
    "    medium_additions_number_constraint = model.solver.interface.Constraint(\n",
    "        optlang.symbolics.Add(*medium_y_vars), lb=0, ub=M, name=\"number_of_medium_additions_constraint\"\n",
    "    )\n",
    "    model.solver.add(medium_additions_number_constraint)\n",
    "    \n",
    "    logger.debug(\"Added constraint for number of knockouts, knockins and medium additions\")\n",
    "\n",
    "    \n",
    "    # Force target control variable to be 1, but allow flux in primal\n",
    "    model.solver.constraints[\"primal_y_const_\" + target + \"_lb\"].lb = -2000\n",
    "    model.solver.constraints[\"primal_y_const_\" + target + \"_ub\"].ub = 2000\n",
    "    model.variables[\"y_\" + target].lb = 1\n",
    "    \n",
    "    return model, native_y_vars, heterologous_y_vars, medium_y_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a388132-363a-4d0f-9634-e1ddb17c2dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete ATPM from fused_model\n",
    "# fused_model.reactions.ATPM.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a72f5836-13fd-4d38-a605-b6329d26c1ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td><strong>Name</strong></td>\n",
       "                <td>iMT1026v3</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Memory address</strong></td>\n",
       "                <td>0x023286b7e7f0</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of metabolites</strong></td>\n",
       "                <td>1708</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of reactions</strong></td>\n",
       "                <td>2240</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of groups</strong></td>\n",
       "                <td>77</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Objective expression</strong></td>\n",
       "                <td>1.0*Ex_biomass - 1.0*Ex_biomass_reverse_5354f</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Compartments</strong></td>\n",
       "                <td>Vacuole, Cytosol, Mitochondria, Peroxisome, Extracellular space, Endoplasmic Reticulum, Golgi Apparatus, Nucleus, Mitochondrial intermembrane space</td>\n",
       "            </tr>\n",
       "          </table>"
      ],
      "text/plain": [
       "<Model iMT1026v3 at 0x23286b7e7f0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fused_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c970b7bb-dbb1-4abc-b0ec-7e71156b8d6a",
   "metadata": {},
   "source": [
    "The meaning of the [Error reading LP format file C:\\Users\\abele\\AppData\\Local\\Temp\\tmphl137a26.lp at line 3284\n",
    "Incomplete constraint\n",
    "Neighboring tokens: \" St - St_reverse_e3a8b - Stm + Stm_reverse_ee872 \"] error is unclear to me. Perhaps it has to do with the lp file format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4be41b2-661b-436e-a3f9-c44a5fdb74a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading LP format file C:\\Users\\abele\\AppData\\Local\\Temp\\tmpkkv7hih2.lp at line 3284\n",
      "Incomplete constraint\n",
      "Neighboring tokens: \" St - St_reverse_e3a8b - Stm + Stm_reverse_ee872 \"\n",
      "\n",
      "Unable to read file\n",
      "Error reading LP format file C:\\Users\\abele\\AppData\\Local\\Temp\\tmp894nxw14.lp at line 3284\n",
      "Incomplete constraint\n",
      "Neighboring tokens: \" St - St_reverse_e3a8b - Stm + Stm_reverse_ee872 \"\n",
      "\n",
      "Unable to read file\n"
     ]
    },
    {
     "ename": "GurobiError",
     "evalue": "Unable to read model",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mGurobiError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\cobra\\core\\model.py\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    409\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 410\u001b[1;33m             \u001b[0mnew\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_solver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    411\u001b[0m             \u001b[1;31m# Cplex has an issue with deep copies\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    171\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m                     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    271\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__setstate__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m             \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\optlang\\gurobi_interface.py\u001b[0m in \u001b[0;36m__setstate__\u001b[1;34m(self, repr_dict)\u001b[0m\n\u001b[0;32m    618\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mTemporaryFilename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\".lp\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrepr_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"lp\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtmp_file_name\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 619\u001b[1;33m             \u001b[0mproblem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgurobipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_file_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    620\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproblem\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mproblem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msrc\\gurobipy\\gurobi.pxi\u001b[0m in \u001b[0;36mgurobipy.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msrc\\gurobipy\\gurobi.pxi\u001b[0m in \u001b[0;36mgurobipy.gurobi.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mGurobiError\u001b[0m: Unable to read model",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mGurobiError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8700/1717529955.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Run the function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmilp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnative_y_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheterologous_y_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmedium_y_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msetup_growthcoupling_milp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfused_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'MSADH'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmedium_metabolites\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mremove_blocked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude_reaction_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexclude_reaction_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8700/1369344116.py\u001b[0m in \u001b[0;36msetup_growthcoupling_milp\u001b[1;34m(model, target, medium_metabolites, K, L, M, exclude_reaction_ids, remove_blocked)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0moriginal_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m# Add boundary reactions for these metabolites named \"ADD_<metabolitename>\" to the model, with bounds (-10,0).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\cobra\\core\\model.py\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    411\u001b[0m             \u001b[1;31m# Cplex has an issue with deep copies\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pragma: no cover\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 413\u001b[1;33m             \u001b[0mnew\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_solver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pragma: no cover\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    414\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[1;31m# it doesn't make sense to retain the context of a copied model so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\copy.py\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    270\u001b[0m             \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__setstate__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m             \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\optlang\\gurobi_interface.py\u001b[0m in \u001b[0;36m__setstate__\u001b[1;34m(self, repr_dict)\u001b[0m\n\u001b[0;32m    617\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepr_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mTemporaryFilename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\".lp\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrepr_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"lp\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtmp_file_name\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 619\u001b[1;33m             \u001b[0mproblem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgurobipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_file_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    620\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproblem\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mproblem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfiguration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConfiguration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msrc\\gurobipy\\gurobi.pxi\u001b[0m in \u001b[0;36mgurobipy.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msrc\\gurobipy\\gurobi.pxi\u001b[0m in \u001b[0;36mgurobipy.gurobi.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mGurobiError\u001b[0m: Unable to read model"
     ]
    }
   ],
   "source": [
    "# Run the function\n",
    "milp, native_y_vars, heterologous_y_vars, medium_y_vars = setup_growthcoupling_milp(fused_model, 'MSADH', medium_metabolites, K=2, L=0, M=0, remove_blocked=False, exclude_reaction_ids=exclude_reaction_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82f6e00-074c-450d-a521-08f0267d4a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "milp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92c2fa3-7615-4968-a600-b6a7f38468b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(native_y_vars), len(heterologous_y_vars), len(medium_y_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f7658e-1018-435b-af89-d5714a5d01f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Solve the MILP problem to retrieve the optimal solution\n",
    "# If speed is important, set a timelimit. Even in a very short time, it will often come up with a solution.\n",
    "# milp.solver.problem.params.TimeLimit = 200\n",
    "from timeit import default_timer as timer\n",
    "start = timer()\n",
    "\n",
    "milp.optimize()\n",
    "\n",
    "end = timer()\n",
    "print(\"Optimization time:\", end - start, \"s\")\n",
    "print(\"Optimization time:\", (end - start)/60, \"m\")\n",
    "print(\"Optimization time:\", (end - start)/3600, \"h\")\n",
    "\n",
    "print(\"MILP objective value:\", milp.objective.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c5591b-603f-4c71-8be6-205561dc464b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(milp.objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247777c2-08ec-4c87-bdfd-ddbc832fd4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in native_y_vars:\n",
    "    if y.primal > 0.99:\n",
    "        print(y, y.primal)\n",
    "        \n",
    "for y in heterologous_y_vars:\n",
    "    if y.primal > 0.99:\n",
    "        print(y, y.primal)\n",
    "\n",
    "for y in medium_y_vars:\n",
    "    if y.primal > 0.99:\n",
    "        print(y, y.primal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3c36fd-6ecb-4148-b12d-2f44dd5a677d",
   "metadata": {},
   "source": [
    "## References\n",
    "[1] Kristian Jensen, Valentijn Broeken, Anne Sofie Lærke Hansen, Nikolaus Sonnenschein, Markus J. Herrgård,\n",
    "OptCouple: Joint simulation of gene knockouts, insertions and medium modifications for prediction of growth-coupled strain designs,\n",
    "Metabolic Engineering Communications,\n",
    "Volume 8,\n",
    "2019,\n",
    "e00087,\n",
    "ISSN 2214-0301,\n",
    "https://doi.org/10.1016/j.mec.2019.e00087."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
